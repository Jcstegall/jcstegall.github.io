<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Project 2 Blog</title>
  <style>
    :root {
      --bg: #0b0d10;
      --card: #12161b;
      --text: #e6edf3;
      --muted: #9aa4af;
      --accent: #7cc0ff;
      --link: #7cc0ff;
      --border: #1f262e;
    }
    html, body {
      margin: 0;
      padding: 0;
      background: var(--bg);
      color: var(--text);
      font: 16px/1.6 system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
    }
    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem 1rem 4rem;
    }
    header h1 {
      margin: 0 0 .5rem;
      font-size: clamp(1.75rem, 2.5vw + 1rem, 2.5rem);
      letter-spacing: .2px;
    }
    header p {
      margin: 0;
      color: var(--muted);
    }
    article {
      margin-top: 2rem;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 1.25rem;
      box-shadow: 0 0 0 1px rgba(255,255,255,0.02) inset;
    }
    h2 {
      margin: 1.5rem 0 .5rem;
      font-size: 1.25rem;
      border-left: 3px solid var(--accent);
      padding-left: .6rem;
    }
    p, li {
      color: var(--text);
    }
    a {
      color: var(--link);
      text-decoration: none;
    }
    a:hover { text-decoration: underline; }
    .meta {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
      color: var(--muted);
      font-size: .95rem;
    }
    .cta {
      display: inline-flex;
      align-items: center;
      gap: .5rem;
      padding: .6rem .9rem;
      background: #0f1720;
      border: 1px solid var(--border);
      border-radius: 8px;
      color: var(--text);
    }
    .visual {
      margin-top: 2rem;
      border: 1px solid var(--border);
      border-radius: 10px;
      overflow: hidden;
      background: #000;
    }
    .visual iframe {
      width: 100%;
      height: 720px;
      border: 0;
      display: block;
      background: #000;
    }
    footer {
      margin-top: 2rem;
      color: var(--muted);
      font-size: .95rem;
    }
  </style>
<style>
  .codebox {
    background: #171b22;
    color: #b5cef7;
    border-radius: 7px;
    border: 1px solid #293241;
    font-family: 'Fira Mono', 'Consolas', 'Menlo', monospace;
    font-size: 1em;
    padding: 1.1em 1.2em;
    margin: 1em 0 1.5em 0;
    overflow-x: auto;
    white-space: pre;
    box-shadow: 0 1px 6px #252d376e;
  }
</style>
</head>
<body>
  <div class="container">
    <header>
      <p class="meta">
        <span>Course: ITIS 3162</span>
        <span>Author: J. C. Stegall</span>
      </p>
    </header>

    <p>
<!-- BEGIN Project2.html sections inserted below -->

<h1>Project 2: Titanic Survival Classification</h1>

<h2>1. Introduction to the Problem</h2>
<p>
This project aims to solve the problem of <strong>predicting whether a passenger survived the Titanic disaster</strong> based on their demographic and travel information.
</p>
<p>
This is a <strong>classification problem</strong> because the target variable (Survived) is categorical (0 = No, 1 = Yes).
</p>
<p>
<strong>Questions:</strong>
</p>
<ul>
  <li>Can we accurately predict if a passenger survived based on their characteristics?</li>
  <li>Which features are most important for survival?</li>
</ul>

<h2>2. Introduction to the Data</h2>
<p>
The data for this problem is the <strong>Titanic dataset</strong>, which contains passenger information (name, age, gender, class, etc.) and survival status.
</p>
<ul>
  <li>Source: <a href="https://www.kaggle.com/c/titanic/data">Kaggle Titanic Dataset</a></li>
  <li>The dataset contains 891 rows and 12 columns.</li>
</ul>
<p>
<strong>Features include:</strong>
</p>
<ul>
  <li><strong>pclass:</strong> Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)</li>
  <li><strong>sex:</strong> Gender</li>
  <li><strong>age:</strong> Age in years</li>
  <li><strong>sibsp:</strong> # of siblings/spouses aboard</li>
  <li><strong>parch:</strong> # of parents/children aboard</li>
  <li><strong>fare:</strong> Passenger fare</li>
  <li><strong>embarked:</strong> Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)</li>
  <li><strong>survived:</strong> Target (0 = No, 1 = Yes)</li>
</ul>

<div class="codebox">
import pandas as pd
import seaborn as sns
data = pd.read_csv("data/titanic.csv")
</div>

<h2>3. Pre-processing the Data</h2>
<p>
Steps:
</p>
<ul>
  <li>Drop irrelevant columns (like name, deck, embark_town).</li>
  <li>Handle missing values in <code>age</code> and <code>embarked</code>.</li>
  <li>Encode categorical variables (sex, class, embarked).</li>
  <li>Ensure target variable is numeric.</li>
</ul>

<div class="codebox">
# Drop unnecessary columns
data = data.drop(columns=["class", "deck", "embark_town", "alive", "adult_male", "who"])

# Handle missing values 
data["age"] = data["age"].fillna(data["age"].median())
data["embarked"] = data["embarked"].fillna(data["embarked"].mode()[0])

# Encode categorical variables
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

for col in ["sex", "embarked"]:
    data[col] = encoder.fit_transform(data[col])

# Drop rows with missing target
data = data.dropna(subset=["survived"])

data.head()
</div>
<img src="images/3_1.png">

<h2>4. Data Understanding / Visualization</h2>
<p>
We will visualize the dataset to explore:
</p>
<ul>
  <li>Survival rate by gender, class, and age.</li>
  <li>Correlation heatmap.</li>
</ul>

<div class="codebox">
import matplotlib.pyplot as plt
import seaborn as sns

# Survival by gender
sns.countplot(x="sex", hue="survived", data=data)
plt.xlabel("Sex (0=Female, 1=Male)")
plt.ylabel("Count")
plt.title("Survival by Gender (0=Did not survive, 1=Survived)")
plt.legend(title="Survived", labels=["No", "Yes"])
plt.show()

# Survival by class
sns.countplot(x="pclass", hue="survived", data=data)
plt.xlabel("Passenger Class")
plt.ylabel("Count")
plt.title("Survival by Class (0=Did not survive, 1=Survived)")
plt.legend(title="Survived", labels=["No", "Yes"])
plt.show()

# Age distribution
sns.histplot(data=data, x="age", hue="survived", bins=30, kde=True)
plt.xlabel("Age")
plt.ylabel("Count")
plt.title("Age Distribution by Survival (0=Did not survive, 1=Survived)")
plt.legend(title="Survived", labels=["No", "Yes"])
plt.show()
</div>
<img src="images/4_1.png">
<img src="images/4_2.png">
<img src="images/4_3.png">
<img>
<img>
<p>
The visualizations reveal several key insights:
</p>
<ul>
  <li><strong>Gender:</strong> Females had a significantly higher survival rate compared to males</li>
  <li><strong>Class:</strong> First-class passengers had the highest survival rate followed by second-class and third-class</li>
  <li><strong>Age:</strong> Children and younger passengers generally had better survival rates</li>
  <li><strong>Correlations:</strong> Strong negative correlation between being male and survival, positive correlation between higher class and survival</li>
</ul>

<h2>5. Modeling</h2>
<p>
These are the three classification models tested: 
<ul>
    <li>Logistic Regression (linear baseline)</li>
    <li>Decision Tree (non-linear, interpretable)</li>
    <li>Random Forest (ensemble, usually more accurate)</li>
</ul>
</p>

<div class="codebox">
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Features and target
X = data.drop("survived", axis=1)
y = data["survived"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)

# Initialize models
log_model = LogisticRegression(max_iter=500)
tree_model = DecisionTreeClassifier(random_state=42)
forest_model = RandomForestClassifier(random_state=42)

# Fit models
log_model.fit(X_train, y_train)
tree_model.fit(X_train, y_train)
forest_model.fit(X_train, y_train)

</div>

<h2>6. Evaluation</h2>
<p>The model will be evaluated by using: 
<ul>
    <li>Accuracy</li>
    <li>Precision, Recall, F1-score</li>
    <li>Confusion Matrix</li>
</ul>
</p>


<div class="codebox">
from sklearn.metrics import classification_report, confusion_matrix

models = {
    "Logistic Regression": log_model,
    "Decision Tree": tree_model,
    "Random Forest": forest_model
}

for name, model in models.items():
    print(f"--- {name} ---")
    y_pred = model.predict(X_test)
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\n")
</div>
<img src="images/6_1.png">
<img src="images/6_2.png">
<img src="images/6_3.png">

<p>All the models performed similarly. They all got around 80% accuracy from a test size of 30% and a random state of 40.</p>

<h2>7. Storytelling</h2>

<p>The models reveal that:  
<ul>
    <li>Women had a much higher survival rate than men</li>
    <li>First-class passengers survived at higher rates than third-class passengers.</li>
    <li>Younger passengers had a better chance of survival</li>
</ul>
</p>


<h2>8. Impact Section</h2>
<p>
Even though this is a historical dataset, the implications extend to real-world applications:  

<ul>
  <li>Social impact: Highlights class and gender inequality during disasters. </li>
  <li>Ethical impact: Predictive models should not be used to justify discriminatory practices.  </li>
  <li>Practical impact: Understanding survival factors can inform future safety policies.</li>
</ul>
</p>

<h2>9. References</h2>
<ul>
  <li>Kaggle Titanic Dataset: <a href="https://www.kaggle.com/c/titanic/data">https://www.kaggle.com/c/titanic/data</a></li>
  <li>Scikit-learn Documentation: <a href="https://scikit-learn.org/">https://scikit-learn.org/</a></li>
  <li>Jupiter Notebook outline created by Chatgpt GPT-5</li>
</ul>

<h2>Appendix</h2>
<a href="https://github.com/Jcstegall/jcstegall.github.io/tree/main/itis3162/pages/Project2">Go to Github Project Folder</a>

<!-- END Project2.html sections inserted above -->
    </article>
  </div>
</body>
</html>